{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cz_item_category', 'item_content_cz', 'item_content_filtered (with_duplicates).csv', 'item_content_filtered_no_duplicates.csv', 'item_content_viewed_sid.csv', 'item_cz', 'item_list.csv', 'list_category', 'material_attributes_cz', 'product_views_cz', 'product_views_cz_filtered.csv', 'product_views_unified.csv', 'sentences.csv']\n"
     ]
    }
   ],
   "source": [
    "import re  # For preprocessing\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import pandas as pd\n",
    "import os\n",
    "os.listdir()\n",
    "print(os.listdir(\"Data/\"))#Contents of the Data folder\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id_anon    product_id\n",
      "0            14723304  100011803451\n",
      "1            14723304  100011612041\n",
      "2            14723304  100016624290\n",
      "3            14723304       1093107\n",
      "4            14723304  100016287573\n",
      "...               ...           ...\n",
      "2999995      57137615       1489324\n",
      "2999996      57137615       1285712\n",
      "2999997      57137615       1489324\n",
      "2999998      57137615       1399946\n",
      "2999999      57137615       1400006\n",
      "\n",
      "[3000000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataFile = \"Data/product_views_unified.csv\"\n",
    "number_rows = 30000000\n",
    "data_2020 = pd.read_csv(dataFile,nrows=number_rows)\n",
    "print(data_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id_anon    product_id\n",
      "0            14723304  100011803451\n",
      "1            14723304  100011612041\n",
      "2            14723304  100016624290\n",
      "3            14723304       1093107\n",
      "4            14723304  100016287573\n",
      "...               ...           ...\n",
      "2999995      57137615       1489324\n",
      "2999996      57137615       1285712\n",
      "2999997      57137615       1489324\n",
      "2999998      57137615       1399946\n",
      "2999999      57137615       1400006\n",
      "\n",
      "[3000000 rows x 2 columns]\n",
      "user_id_anon\n",
      "645         [655028, 1338684, 100018643178, 100018644575, ...\n",
      "788         [100016425290, 452568001, 1086821, 1403084, 14...\n",
      "871         [551806, 1305893, 1293084, 1389660, 1510064, 1...\n",
      "1345        [100018205007, 100018206462, 100018206445, 100...\n",
      "2981        [1480352, 1419661, 1105542, 1419654, 666213, 1...\n",
      "                                  ...                        \n",
      "62563472    [1349506, 1349510, 1349506, 1397954, 1490283, ...\n",
      "62563934    [100016141442, 100016143151, 100016145005, 100...\n",
      "62565140    [1236035, 100002172473, 645720, 100002786928, ...\n",
      "62565992    [1339130, 1330960002, 1330960002, 1330960002, ...\n",
      "62570516    [1327813005, 1327813005, 673184004, 1455333, 1...\n",
      "Name: product_id, Length: 62897, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_2020['product_id'] = data_2020.loc[:,'product_id'].map(str)\n",
    "print(data_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data_2020.groupby('user_id_anon')['product_id'].apply(list)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100024602647\n"
     ]
    }
   ],
   "source": [
    "most_viewed_element = data_2020[\"product_id\"].value_counts().idxmax()\n",
    "print(most_viewed_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "# w2v_model = Word2Vec(min_count=10,\n",
    "#                      window=2,\n",
    "#                      size=300,\n",
    "#                      sample=6e-5, \n",
    "#                      alpha=0.05, \n",
    "#                      min_alpha=0.001, \n",
    "#                      negative=20,\n",
    "#                      workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_anon\n",
      "538256      [810546003, 810546003, 810546003, 810546003, 8...\n",
      "889903      [100019753972, 100019305254, 100019974986, 100...\n",
      "1478904     [1027666, 660649, 1027666, 1033245, 888073, 10...\n",
      "1701672     [100020173950, 100029044379, 100029488800, 135...\n",
      "4631801     [100016830262, 100016830262, 1223934, 10001683...\n",
      "7127098     [1369991002, 1421387001, 1421387001, 116221900...\n",
      "11350299    [100011304333, 1044888, 100013838783, 10001515...\n",
      "15351895    [100018404773, 1247174, 1107042, 100015799314,...\n",
      "17423924    [632960, 448602, 602001, 448602, 116350, 11095...\n",
      "17618864    [969804001, 100019839747, 1273164, 1124037001,...\n",
      "17685842    [996042, 492205, 1034216002, 1034216002, 10342...\n",
      "21410504    [100016284804, 100011744558, 100004210791, 133...\n",
      "23126675    [100022944375, 100022675574, 100017721476, 100...\n",
      "25653713    [1102404004, 1102404004, 870690, 1318363, 1102...\n",
      "27428334    [1416624, 100019173290, 489961, 726649, 100004...\n",
      "31899327    [789166, 131864, 100012106631, 1049771, 760493...\n",
      "38210986    [100017824132, 1426210, 1406598, 1405857, 1183...\n",
      "38515823    [2333279, 2333279, 2333279, 2333279, 2333279, ...\n",
      "44050834    [100031854875, 100004738415, 1004954, 15010370...\n",
      "49162360    [100003687693, 100002736204, 100002668353, 100...\n",
      "52904649    [1297334, 1370765, 1297210, 1209841, 2540899, ...\n",
      "57137615                          [1400006, 1400006, 1282437]\n",
      "58033772    [100011612744, 1365866, 1825683, 483085, 13512...\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataFile = \"Data/product_views_unified.csv\"\n",
    "test_rows = 31502086 - number_rows\n",
    "test_data = pd.read_csv(dataFile,names=[\"user_id_anon\",\"product_id\"],skiprows=number_rows,nrows=1000000)\n",
    "test_data['product_id'] = test_data.loc[:,'product_id'].map(str)\n",
    "test_set = test_data.groupby('user_id_anon')['product_id'].apply(list)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "parm_dict = {'size':(100,200,300),'window':(2,5),'min_count':(5,10),'alpha':(0.03,0.02,0.01)}\n",
    "\n",
    "def cust_param_search(parm_dict,sentences,test_set,most_viewed_element):\n",
    "    score_best, parm_best = 0,()\n",
    "   \n",
    "    size,window, min_count, alpha = [tup for k,tup in parm_dict.items()] # Individual parm tuples\n",
    "\n",
    "    parm_combo = list(itertools.product(size,window, min_count, alpha)) # Create all combinations\n",
    "\n",
    "    for parms in parm_combo:\n",
    "        s, w, m, a = parms\n",
    "        print (parms)\n",
    "        model = Word2Vec(min_count=m,\n",
    "                         window=w,\n",
    "                         size=s,\n",
    "                         alpha=a,\n",
    "                         workers=cores-1)\n",
    "        model.build_vocab(sentences, progress_per=5000)\n",
    "        model.train(sentences, total_examples=model.corpus_count, epochs=10, report_delay=1)\n",
    "\n",
    "        model.init_sims(replace=True)\n",
    "        similarity = []\n",
    "        for i in test_set: #SCORE FUNCTION pro nejvíce viděný produkt oproti všem ostatním\n",
    "            simil = []\n",
    "            for j in i:\n",
    "                if j in model.wv.vocab and j != most_viewed_element:\n",
    "#                     print(model.wv.similarity(most_viewed_element,j))\n",
    "                    simil.append(model.wv.similarity(most_viewed_element,j))\n",
    "            if len(simil)>0:\n",
    "                similarity.append(sum(simil)/len(simil))\n",
    "        \n",
    "        score = sum(similarity)/len(similarity)\n",
    "        print(score)\n",
    "\n",
    "        if score > score_best:\n",
    "            score_best = score\n",
    "            parm_best = parms          \n",
    "    print(\"Best score -\",score_best, \"Best parms - \",parm_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:59:53: collecting all words and their counts\n",
      "INFO - 13:59:53: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 13:59:53: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:59:53: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 13:59:54: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 13:59:55: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 13:59:55: Loading a fresh vocabulary\n",
      "INFO - 13:59:55: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 13:59:55: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 13:59:56: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 13:59:56: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 13:59:56: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 13:59:57: estimated required memory for 108857 words and 100 dimensions: 141514100 bytes\n",
      "INFO - 13:59:57: resetting layer weights\n",
      "INFO - 14:00:28: training model with 3 workers on 108857 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:00:32: EPOCH 1 - PROGRESS: at 15.47% examples, 396394 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:33: EPOCH 1 - PROGRESS: at 39.20% examples, 503734 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:34: EPOCH 1 - PROGRESS: at 63.04% examples, 540123 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:00:35: EPOCH 1 - PROGRESS: at 87.95% examples, 561377 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:00:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:00:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:00:36: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 4.5s, 571745 effective words/s\n",
      "INFO - 14:00:37: EPOCH 2 - PROGRESS: at 25.03% examples, 637995 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:38: EPOCH 2 - PROGRESS: at 49.33% examples, 631244 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:39: EPOCH 2 - PROGRESS: at 74.52% examples, 631962 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:00:40: EPOCH 2 - PROGRESS: at 98.17% examples, 622243 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:00:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:00:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:00:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:00:40: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 4.1s, 621950 effective words/s\n",
      "INFO - 14:00:40: training on a 6000000 raw words (5129408 effective words) took 12.3s, 417097 effective words/s\n",
      "INFO - 14:00:40: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:00:40: collecting all words and their counts\n",
      "INFO - 14:00:40: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:00:40: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5439323033122107\n",
      "(100, 2, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:00:40: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:00:40: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:00:41: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:00:42: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:00:42: Loading a fresh vocabulary\n",
      "INFO - 14:00:42: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:00:42: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:00:43: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:00:43: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:00:43: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:00:43: estimated required memory for 108857 words and 100 dimensions: 141514100 bytes\n",
      "INFO - 14:00:43: resetting layer weights\n",
      "INFO - 14:01:13: training model with 3 workers on 108857 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:01:14: EPOCH 1 - PROGRESS: at 24.71% examples, 624840 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:15: EPOCH 1 - PROGRESS: at 48.69% examples, 622759 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:16: EPOCH 1 - PROGRESS: at 73.63% examples, 621246 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:17: EPOCH 1 - PROGRESS: at 98.17% examples, 623156 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:01:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:01:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:01:17: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 4.1s, 626654 effective words/s\n",
      "INFO - 14:01:18: EPOCH 2 - PROGRESS: at 25.34% examples, 641153 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:19: EPOCH 2 - PROGRESS: at 49.67% examples, 634501 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:20: EPOCH 2 - PROGRESS: at 75.22% examples, 634176 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 14:01:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:01:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:01:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:01:21: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 4.0s, 640155 effective words/s\n",
      "INFO - 14:01:21: training on a 6000000 raw words (5129408 effective words) took 8.1s, 632432 effective words/s\n",
      "INFO - 14:01:21: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:01:21: collecting all words and their counts\n",
      "INFO - 14:01:21: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:01:21: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:01:21: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4939026568649142\n",
      "(100, 2, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:01:21: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:01:21: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:01:21: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:01:22: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:01:22: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:01:22: Loading a fresh vocabulary\n",
      "INFO - 14:01:23: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:01:23: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:01:23: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:01:23: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:01:23: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:01:23: estimated required memory for 60943 words and 100 dimensions: 79225900 bytes\n",
      "INFO - 14:01:23: resetting layer weights\n",
      "INFO - 14:01:40: training model with 3 workers on 60943 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:01:41: EPOCH 1 - PROGRESS: at 29.79% examples, 674162 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:42: EPOCH 1 - PROGRESS: at 60.03% examples, 673818 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:01:43: EPOCH 1 - PROGRESS: at 89.26% examples, 665130 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:01:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:01:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:01:44: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 3.4s, 666399 effective words/s\n",
      "INFO - 14:01:45: EPOCH 2 - PROGRESS: at 25.65% examples, 575936 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:01:46: EPOCH 2 - PROGRESS: at 55.43% examples, 621436 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:47: EPOCH 2 - PROGRESS: at 79.23% examples, 587760 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:01:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:01:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:01:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:01:48: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 4.0s, 566119 effective words/s\n",
      "INFO - 14:01:48: training on a 6000000 raw words (4502374 effective words) took 7.4s, 610961 effective words/s\n",
      "INFO - 14:01:48: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:01:48: collecting all words and their counts\n",
      "INFO - 14:01:48: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:01:48: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4520027766131087\n",
      "(100, 2, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:01:48: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:01:48: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:01:48: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:01:48: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:01:49: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:01:49: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:01:49: Loading a fresh vocabulary\n",
      "INFO - 14:01:50: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:01:50: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:01:50: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:01:50: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:01:50: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:01:50: estimated required memory for 60943 words and 100 dimensions: 79225900 bytes\n",
      "INFO - 14:01:50: resetting layer weights\n",
      "INFO - 14:02:07: training model with 3 workers on 60943 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:02:08: EPOCH 1 - PROGRESS: at 27.27% examples, 612764 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:09: EPOCH 1 - PROGRESS: at 56.79% examples, 633561 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:10: EPOCH 1 - PROGRESS: at 87.27% examples, 647534 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:02:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:02:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:02:10: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 3.4s, 654248 effective words/s\n",
      "INFO - 14:02:11: EPOCH 2 - PROGRESS: at 29.54% examples, 663009 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:12: EPOCH 2 - PROGRESS: at 60.03% examples, 672652 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:13: EPOCH 2 - PROGRESS: at 89.59% examples, 665624 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:02:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:02:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:02:13: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 3.4s, 667856 effective words/s\n",
      "INFO - 14:02:13: training on a 6000000 raw words (4502374 effective words) took 6.8s, 659585 effective words/s\n",
      "INFO - 14:02:13: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:02:14: collecting all words and their counts\n",
      "INFO - 14:02:14: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7968456755746706\n",
      "(100, 5, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:14: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:02:14: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:02:15: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:02:15: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:02:15: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:02:15: Loading a fresh vocabulary\n",
      "INFO - 14:02:15: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:02:15: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:02:16: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:02:16: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:02:16: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:02:16: estimated required memory for 108857 words and 100 dimensions: 141514100 bytes\n",
      "INFO - 14:02:16: resetting layer weights\n",
      "INFO - 14:02:47: training model with 3 workers on 108857 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:02:48: EPOCH 1 - PROGRESS: at 23.78% examples, 598476 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:02:49: EPOCH 1 - PROGRESS: at 48.38% examples, 610454 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:50: EPOCH 1 - PROGRESS: at 72.98% examples, 612527 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:51: EPOCH 1 - PROGRESS: at 97.47% examples, 615750 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:02:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:02:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:02:51: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 4.2s, 615330 effective words/s\n",
      "INFO - 14:02:52: EPOCH 2 - PROGRESS: at 23.78% examples, 601479 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:02:53: EPOCH 2 - PROGRESS: at 46.39% examples, 592325 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:54: EPOCH 2 - PROGRESS: at 71.33% examples, 600860 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:55: EPOCH 2 - PROGRESS: at 95.14% examples, 603096 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:02:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:02:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:02:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:02:55: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 4.2s, 604865 effective words/s\n",
      "INFO - 14:02:55: training on a 6000000 raw words (5129408 effective words) took 8.4s, 608777 effective words/s\n",
      "INFO - 14:02:55: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:02:55: collecting all words and their counts\n",
      "INFO - 14:02:55: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:02:55: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45074434490944026\n",
      "(100, 5, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:02:56: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:02:56: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:02:56: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:02:56: Loading a fresh vocabulary\n",
      "INFO - 14:02:57: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:02:57: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:02:57: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:02:57: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:02:57: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:02:58: estimated required memory for 108857 words and 100 dimensions: 141514100 bytes\n",
      "INFO - 14:02:58: resetting layer weights\n",
      "INFO - 14:03:28: training model with 3 workers on 108857 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:03:30: EPOCH 1 - PROGRESS: at 23.78% examples, 600347 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:31: EPOCH 1 - PROGRESS: at 46.39% examples, 593190 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:32: EPOCH 1 - PROGRESS: at 70.97% examples, 599081 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:33: EPOCH 1 - PROGRESS: at 95.14% examples, 602461 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:03:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:03:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:03:33: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 4.2s, 603973 effective words/s\n",
      "INFO - 14:03:34: EPOCH 2 - PROGRESS: at 23.78% examples, 604512 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:35: EPOCH 2 - PROGRESS: at 47.74% examples, 610772 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:03:36: EPOCH 2 - PROGRESS: at 71.97% examples, 610541 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:37: EPOCH 2 - PROGRESS: at 96.14% examples, 611491 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:03:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:03:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:03:37: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 4.2s, 614041 effective words/s\n",
      "INFO - 14:03:37: training on a 6000000 raw words (5129408 effective words) took 8.4s, 608001 effective words/s\n",
      "INFO - 14:03:37: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:03:37: collecting all words and their counts\n",
      "INFO - 14:03:37: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:03:37: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:03:37: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8342840946043798\n",
      "(100, 5, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:03:37: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:03:37: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:03:37: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:03:38: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:03:38: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:03:38: Loading a fresh vocabulary\n",
      "INFO - 14:03:39: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:03:39: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:03:39: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:03:39: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:03:39: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:03:39: estimated required memory for 60943 words and 100 dimensions: 79225900 bytes\n",
      "INFO - 14:03:39: resetting layer weights\n",
      "INFO - 14:03:57: training model with 3 workers on 60943 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:03:58: EPOCH 1 - PROGRESS: at 26.96% examples, 608472 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:03:59: EPOCH 1 - PROGRESS: at 50.02% examples, 562580 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:04:00: EPOCH 1 - PROGRESS: at 71.63% examples, 533147 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:01: EPOCH 1 - PROGRESS: at 93.12% examples, 519656 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:01: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 4.4s, 512980 effective words/s\n",
      "INFO - 14:04:02: EPOCH 2 - PROGRESS: at 25.34% examples, 570753 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:04:03: EPOCH 2 - PROGRESS: at 53.48% examples, 602435 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:04: EPOCH 2 - PROGRESS: at 74.54% examples, 557152 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:05: EPOCH 2 - PROGRESS: at 96.47% examples, 540844 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:04:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:05: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 4.2s, 539811 effective words/s\n",
      "INFO - 14:04:05: training on a 6000000 raw words (4502374 effective words) took 8.6s, 525169 effective words/s\n",
      "INFO - 14:04:05: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:04:05: collecting all words and their counts\n",
      "INFO - 14:04:05: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:04:05: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3402780609447153\n",
      "(100, 5, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:05: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:04:06: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:04:06: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:04:06: Loading a fresh vocabulary\n",
      "INFO - 14:04:07: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:04:07: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:04:07: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:04:07: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:04:07: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:04:07: estimated required memory for 60943 words and 100 dimensions: 79225900 bytes\n",
      "INFO - 14:04:07: resetting layer weights\n",
      "INFO - 14:04:27: training model with 3 workers on 60943 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:04:28: EPOCH 1 - PROGRESS: at 28.23% examples, 630848 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:04:29: EPOCH 1 - PROGRESS: at 56.80% examples, 634664 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:30: EPOCH 1 - PROGRESS: at 85.91% examples, 637120 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:31: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 3.5s, 635823 effective words/s\n",
      "INFO - 14:04:32: EPOCH 2 - PROGRESS: at 26.96% examples, 605894 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:33: EPOCH 2 - PROGRESS: at 51.38% examples, 578259 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:34: EPOCH 2 - PROGRESS: at 76.56% examples, 568934 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:04:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:04:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:04:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:04:35: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 4.0s, 564070 effective words/s\n",
      "INFO - 14:04:35: training on a 6000000 raw words (4502374 effective words) took 7.5s, 596413 effective words/s\n",
      "INFO - 14:04:35: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:04:35: collecting all words and their counts\n",
      "INFO - 14:04:35: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:04:35: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7299358689021399\n",
      "(200, 2, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:04:35: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:04:35: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:04:35: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:04:35: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:04:36: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:04:36: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:04:36: Loading a fresh vocabulary\n",
      "INFO - 14:04:37: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:04:37: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:04:38: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:04:38: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:04:38: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:04:38: estimated required memory for 108857 words and 200 dimensions: 228599700 bytes\n",
      "INFO - 14:04:38: resetting layer weights\n",
      "INFO - 14:05:11: training model with 3 workers on 108857 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:05:12: EPOCH 1 - PROGRESS: at 17.78% examples, 456893 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:13: EPOCH 1 - PROGRESS: at 33.84% examples, 434057 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:14: EPOCH 1 - PROGRESS: at 49.33% examples, 420721 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:15: EPOCH 1 - PROGRESS: at 66.43% examples, 423348 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:16: EPOCH 1 - PROGRESS: at 82.94% examples, 420656 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:05:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:05:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:05:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:05:17: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 6.0s, 424154 effective words/s\n",
      "INFO - 14:05:18: EPOCH 2 - PROGRESS: at 17.78% examples, 445502 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:19: EPOCH 2 - PROGRESS: at 35.45% examples, 446634 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:20: EPOCH 2 - PROGRESS: at 54.17% examples, 456072 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:21: EPOCH 2 - PROGRESS: at 71.63% examples, 450674 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:05:22: EPOCH 2 - PROGRESS: at 88.60% examples, 446337 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:05:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:05:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:05:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:05:23: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 5.8s, 441956 effective words/s\n",
      "INFO - 14:05:23: training on a 6000000 raw words (5129408 effective words) took 11.9s, 432272 effective words/s\n",
      "INFO - 14:05:23: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:05:23: collecting all words and their counts\n",
      "INFO - 14:05:23: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:05:23: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5594461811018056\n",
      "(200, 2, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:05:23: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:05:23: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:05:23: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:05:24: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:05:24: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:05:24: Loading a fresh vocabulary\n",
      "INFO - 14:05:25: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:05:25: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:05:25: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:05:25: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:05:25: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:05:26: estimated required memory for 108857 words and 200 dimensions: 228599700 bytes\n",
      "INFO - 14:05:26: resetting layer weights\n",
      "INFO - 14:05:57: training model with 3 workers on 108857 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:05:59: EPOCH 1 - PROGRESS: at 18.40% examples, 466078 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:00: EPOCH 1 - PROGRESS: at 37.16% examples, 471740 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:01: EPOCH 1 - PROGRESS: at 55.43% examples, 469320 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:02: EPOCH 1 - PROGRESS: at 74.52% examples, 469759 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:03: EPOCH 1 - PROGRESS: at 93.12% examples, 470063 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:03: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 5.4s, 471242 effective words/s\n",
      "INFO - 14:06:04: EPOCH 2 - PROGRESS: at 17.44% examples, 443885 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:05: EPOCH 2 - PROGRESS: at 36.12% examples, 460406 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:06: EPOCH 2 - PROGRESS: at 54.45% examples, 458854 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:07: EPOCH 2 - PROGRESS: at 73.25% examples, 460851 words/s, in_qsize 5, out_qsize 2\n",
      "INFO - 14:06:08: EPOCH 2 - PROGRESS: at 92.12% examples, 465227 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:08: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 5.5s, 466231 effective words/s\n",
      "INFO - 14:06:08: training on a 6000000 raw words (5129408 effective words) took 11.0s, 468086 effective words/s\n",
      "INFO - 14:06:08: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:06:09: collecting all words and their counts\n",
      "INFO - 14:06:09: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47134505002750277\n",
      "(200, 2, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:06:09: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:06:09: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:06:10: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:06:10: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:06:10: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:06:10: Loading a fresh vocabulary\n",
      "INFO - 14:06:10: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:06:10: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:06:10: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:06:10: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:06:10: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:06:11: estimated required memory for 60943 words and 200 dimensions: 127980300 bytes\n",
      "INFO - 14:06:11: resetting layer weights\n",
      "INFO - 14:06:27: training model with 3 workers on 60943 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:06:28: EPOCH 1 - PROGRESS: at 21.09% examples, 472574 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:06:29: EPOCH 1 - PROGRESS: at 40.21% examples, 446340 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:30: EPOCH 1 - PROGRESS: at 61.69% examples, 455907 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:31: EPOCH 1 - PROGRESS: at 82.27% examples, 455166 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 14:06:32: EPOCH 1 - PROGRESS: at 98.81% examples, 437418 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 14:06:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:32: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 5.1s, 438148 effective words/s\n",
      "INFO - 14:06:34: EPOCH 2 - PROGRESS: at 16.12% examples, 356084 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:35: EPOCH 2 - PROGRESS: at 31.12% examples, 345851 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:36: EPOCH 2 - PROGRESS: at 49.03% examples, 362286 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:37: EPOCH 2 - PROGRESS: at 70.28% examples, 388485 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:38: EPOCH 2 - PROGRESS: at 88.95% examples, 393946 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:06:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:06:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:06:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:06:38: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 5.8s, 390576 effective words/s\n",
      "INFO - 14:06:38: training on a 6000000 raw words (4502374 effective words) took 10.9s, 412440 effective words/s\n",
      "INFO - 14:06:38: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:06:38: collecting all words and their counts\n",
      "INFO - 14:06:38: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466466062192908\n",
      "(200, 2, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:06:39: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:06:39: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:06:40: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:06:40: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:06:40: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:06:40: Loading a fresh vocabulary\n",
      "INFO - 14:06:40: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:06:40: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:06:40: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:06:40: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:06:40: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:06:41: estimated required memory for 60943 words and 200 dimensions: 127980300 bytes\n",
      "INFO - 14:06:41: resetting layer weights\n",
      "INFO - 14:06:58: training model with 3 workers on 60943 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:06:59: EPOCH 1 - PROGRESS: at 20.08% examples, 444520 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:00: EPOCH 1 - PROGRESS: at 41.54% examples, 462981 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:01: EPOCH 1 - PROGRESS: at 63.04% examples, 469227 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:02: EPOCH 1 - PROGRESS: at 82.60% examples, 460295 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:03: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 4.9s, 454933 effective words/s\n",
      "INFO - 14:07:04: EPOCH 2 - PROGRESS: at 18.40% examples, 416441 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:05: EPOCH 2 - PROGRESS: at 39.20% examples, 442204 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:07:06: EPOCH 2 - PROGRESS: at 59.12% examples, 443291 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:07: EPOCH 2 - PROGRESS: at 79.23% examples, 442925 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:08: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 5.0s, 448749 effective words/s\n",
      "INFO - 14:07:08: training on a 6000000 raw words (4502374 effective words) took 10.0s, 451106 effective words/s\n",
      "INFO - 14:07:08: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:07:08: collecting all words and their counts\n",
      "INFO - 14:07:08: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:07:08: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:07:08: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788443013496567\n",
      "(200, 5, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:07:08: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:07:09: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:07:09: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:07:09: Loading a fresh vocabulary\n",
      "INFO - 14:07:10: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:07:10: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:07:11: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:07:11: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:07:11: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:07:11: estimated required memory for 108857 words and 200 dimensions: 228599700 bytes\n",
      "INFO - 14:07:11: resetting layer weights\n",
      "INFO - 14:07:43: training model with 3 workers on 108857 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:07:44: EPOCH 1 - PROGRESS: at 16.79% examples, 431320 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:45: EPOCH 1 - PROGRESS: at 33.12% examples, 425481 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:46: EPOCH 1 - PROGRESS: at 50.32% examples, 429412 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:47: EPOCH 1 - PROGRESS: at 68.53% examples, 434402 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:48: EPOCH 1 - PROGRESS: at 86.26% examples, 435854 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:49: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 5.9s, 435651 effective words/s\n",
      "INFO - 14:07:50: EPOCH 2 - PROGRESS: at 14.81% examples, 370937 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:51: EPOCH 2 - PROGRESS: at 31.12% examples, 394175 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:52: EPOCH 2 - PROGRESS: at 49.03% examples, 412671 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:07:53: EPOCH 2 - PROGRESS: at 67.13% examples, 422501 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:07:54: EPOCH 2 - PROGRESS: at 84.85% examples, 427535 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:07:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:07:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:07:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:07:55: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 5.9s, 432255 effective words/s\n",
      "INFO - 14:07:55: training on a 6000000 raw words (5129408 effective words) took 11.8s, 433451 effective words/s\n",
      "INFO - 14:07:55: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:07:55: collecting all words and their counts\n",
      "INFO - 14:07:55: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:07:55: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4164095528646195\n",
      "(200, 5, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:07:55: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:07:55: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:07:56: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:07:56: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:07:56: Loading a fresh vocabulary\n",
      "INFO - 14:07:57: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:07:57: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:07:58: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:07:58: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:07:58: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:07:58: estimated required memory for 108857 words and 200 dimensions: 228599700 bytes\n",
      "INFO - 14:07:58: resetting layer weights\n",
      "INFO - 14:08:29: training model with 3 workers on 108857 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:08:30: EPOCH 1 - PROGRESS: at 15.47% examples, 392192 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:31: EPOCH 1 - PROGRESS: at 31.78% examples, 406670 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:32: EPOCH 1 - PROGRESS: at 48.38% examples, 411204 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:33: EPOCH 1 - PROGRESS: at 66.43% examples, 421800 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:34: EPOCH 1 - PROGRESS: at 83.61% examples, 423767 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:08:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:08:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:08:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:08:35: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 6.0s, 424876 effective words/s\n",
      "INFO - 14:08:36: EPOCH 2 - PROGRESS: at 13.43% examples, 342912 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:37: EPOCH 2 - PROGRESS: at 27.27% examples, 346511 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:38: EPOCH 2 - PROGRESS: at 42.49% examples, 360752 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:39: EPOCH 2 - PROGRESS: at 58.78% examples, 372154 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:40: EPOCH 2 - PROGRESS: at 76.56% examples, 386074 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:41: EPOCH 2 - PROGRESS: at 94.48% examples, 397762 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:08:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:08:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:08:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:08:41: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 6.4s, 400795 effective words/s\n",
      "INFO - 14:08:41: training on a 6000000 raw words (5129408 effective words) took 12.5s, 411774 effective words/s\n",
      "INFO - 14:08:41: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:08:41: collecting all words and their counts\n",
      "INFO - 14:08:41: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:08:41: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8351309505773115\n",
      "(200, 5, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:08:41: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:08:41: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:08:42: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:08:42: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:08:42: Loading a fresh vocabulary\n",
      "INFO - 14:08:43: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:08:43: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:08:43: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:08:43: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:08:43: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:08:43: estimated required memory for 60943 words and 200 dimensions: 127980300 bytes\n",
      "INFO - 14:08:43: resetting layer weights\n",
      "INFO - 14:09:02: training model with 3 workers on 60943 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:09:03: EPOCH 1 - PROGRESS: at 15.15% examples, 334794 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:04: EPOCH 1 - PROGRESS: at 30.80% examples, 342940 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:05: EPOCH 1 - PROGRESS: at 46.74% examples, 346832 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:06: EPOCH 1 - PROGRESS: at 62.01% examples, 343250 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:07: EPOCH 1 - PROGRESS: at 79.23% examples, 349497 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:09:08: EPOCH 1 - PROGRESS: at 97.49% examples, 358450 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:09:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:09:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:09:09: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 6.2s, 361343 effective words/s\n",
      "INFO - 14:09:10: EPOCH 2 - PROGRESS: at 15.83% examples, 351562 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:11: EPOCH 2 - PROGRESS: at 31.12% examples, 347729 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:12: EPOCH 2 - PROGRESS: at 50.02% examples, 369850 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:13: EPOCH 2 - PROGRESS: at 70.92% examples, 390611 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:14: EPOCH 2 - PROGRESS: at 89.26% examples, 393332 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:09:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:09:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:09:14: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 5.7s, 396457 effective words/s\n",
      "INFO - 14:09:14: training on a 6000000 raw words (4502374 effective words) took 11.9s, 377623 effective words/s\n",
      "INFO - 14:09:14: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:09:14: collecting all words and their counts\n",
      "INFO - 14:09:14: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:09:14: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3659926620273501\n",
      "(200, 5, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:09:15: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:09:15: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:09:16: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:09:16: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:09:16: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:09:16: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:09:16: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:09:16: Loading a fresh vocabulary\n",
      "INFO - 14:09:16: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:09:16: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:09:17: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:09:17: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:09:17: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:09:17: estimated required memory for 60943 words and 200 dimensions: 127980300 bytes\n",
      "INFO - 14:09:17: resetting layer weights\n",
      "INFO - 14:09:34: training model with 3 workers on 60943 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:09:35: EPOCH 1 - PROGRESS: at 20.08% examples, 452820 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 14:09:36: EPOCH 1 - PROGRESS: at 40.84% examples, 456069 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:09:37: EPOCH 1 - PROGRESS: at 61.69% examples, 458982 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:38: EPOCH 1 - PROGRESS: at 83.29% examples, 462387 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:09:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:09:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:09:39: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 4.9s, 464109 effective words/s\n",
      "INFO - 14:09:40: EPOCH 2 - PROGRESS: at 20.71% examples, 454813 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:41: EPOCH 2 - PROGRESS: at 41.80% examples, 462191 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:42: EPOCH 2 - PROGRESS: at 62.69% examples, 464714 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:43: EPOCH 2 - PROGRESS: at 83.94% examples, 465114 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:09:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:09:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:09:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:09:44: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 4.8s, 465342 effective words/s\n",
      "INFO - 14:09:44: training on a 6000000 raw words (4502374 effective words) took 9.7s, 464104 effective words/s\n",
      "INFO - 14:09:44: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:09:44: collecting all words and their counts\n",
      "INFO - 14:09:44: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:09:44: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:09:44: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7603568364126323\n",
      "(300, 2, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:09:45: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:09:45: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:09:45: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:09:45: Loading a fresh vocabulary\n",
      "INFO - 14:09:46: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:09:46: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:09:47: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:09:47: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:09:47: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:09:47: estimated required memory for 108857 words and 300 dimensions: 315685300 bytes\n",
      "INFO - 14:09:47: resetting layer weights\n",
      "INFO - 14:10:17: training model with 3 workers on 108857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:10:18: EPOCH 1 - PROGRESS: at 12.15% examples, 313911 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:19: EPOCH 1 - PROGRESS: at 25.34% examples, 324305 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:20: EPOCH 1 - PROGRESS: at 39.20% examples, 334470 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:21: EPOCH 1 - PROGRESS: at 53.12% examples, 335917 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:10:22: EPOCH 1 - PROGRESS: at 66.76% examples, 338354 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:23: EPOCH 1 - PROGRESS: at 81.33% examples, 342786 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:24: EPOCH 1 - PROGRESS: at 93.43% examples, 338017 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:10:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:10:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:10:24: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 7.7s, 333979 effective words/s\n",
      "INFO - 14:10:25: EPOCH 2 - PROGRESS: at 12.82% examples, 327038 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:26: EPOCH 2 - PROGRESS: at 23.78% examples, 297180 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:10:27: EPOCH 2 - PROGRESS: at 35.11% examples, 296655 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:28: EPOCH 2 - PROGRESS: at 47.07% examples, 298737 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:10:29: EPOCH 2 - PROGRESS: at 59.45% examples, 301815 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:10:30: EPOCH 2 - PROGRESS: at 70.62% examples, 295566 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:31: EPOCH 2 - PROGRESS: at 81.96% examples, 294360 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:10:32: EPOCH 2 - PROGRESS: at 95.50% examples, 300149 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:10:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:10:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:10:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:10:33: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 8.5s, 302549 effective words/s\n",
      "INFO - 14:10:33: training on a 6000000 raw words (5129408 effective words) took 16.2s, 317162 effective words/s\n",
      "INFO - 14:10:33: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:10:33: collecting all words and their counts\n",
      "INFO - 14:10:33: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:10:33: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:10:33: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5639753709564116\n",
      "(300, 2, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:10:33: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:10:33: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:10:33: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:10:34: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:10:34: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:10:34: Loading a fresh vocabulary\n",
      "INFO - 14:10:35: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:10:35: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:10:35: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:10:35: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:10:35: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:10:36: estimated required memory for 108857 words and 300 dimensions: 315685300 bytes\n",
      "INFO - 14:10:36: resetting layer weights\n",
      "INFO - 14:11:12: training model with 3 workers on 108857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:11:13: EPOCH 1 - PROGRESS: at 13.75% examples, 348191 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:14: EPOCH 1 - PROGRESS: at 27.63% examples, 352170 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:15: EPOCH 1 - PROGRESS: at 41.54% examples, 351264 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:16: EPOCH 1 - PROGRESS: at 55.08% examples, 350613 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:17: EPOCH 1 - PROGRESS: at 69.24% examples, 351091 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:18: EPOCH 1 - PROGRESS: at 83.94% examples, 353463 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:19: EPOCH 1 - PROGRESS: at 97.47% examples, 350941 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:11:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:11:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:11:19: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 7.3s, 352551 effective words/s\n",
      "INFO - 14:11:20: EPOCH 2 - PROGRESS: at 12.82% examples, 329547 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:21: EPOCH 2 - PROGRESS: at 26.95% examples, 344150 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:22: EPOCH 2 - PROGRESS: at 41.20% examples, 351369 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:23: EPOCH 2 - PROGRESS: at 55.08% examples, 352822 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:24: EPOCH 2 - PROGRESS: at 69.24% examples, 353022 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:25: EPOCH 2 - PROGRESS: at 81.64% examples, 346413 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:26: EPOCH 2 - PROGRESS: at 93.12% examples, 339024 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:11:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:11:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:11:27: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 7.7s, 334615 effective words/s\n",
      "INFO - 14:11:27: training on a 6000000 raw words (5129408 effective words) took 15.0s, 343028 effective words/s\n",
      "INFO - 14:11:27: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:11:27: collecting all words and their counts\n",
      "INFO - 14:11:27: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:11:27: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:11:27: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4436586401152169\n",
      "(300, 2, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:11:27: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:11:27: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:11:28: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:11:29: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:11:29: Loading a fresh vocabulary\n",
      "INFO - 14:11:29: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:11:29: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:11:29: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:11:29: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:11:29: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:11:30: estimated required memory for 60943 words and 300 dimensions: 176734700 bytes\n",
      "INFO - 14:11:30: resetting layer weights\n",
      "INFO - 14:11:51: training model with 3 workers on 60943 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:11:52: EPOCH 1 - PROGRESS: at 13.12% examples, 295919 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:53: EPOCH 1 - PROGRESS: at 28.58% examples, 322698 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:54: EPOCH 1 - PROGRESS: at 45.09% examples, 336063 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:55: EPOCH 1 - PROGRESS: at 61.69% examples, 344903 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:56: EPOCH 1 - PROGRESS: at 78.24% examples, 346377 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:57: EPOCH 1 - PROGRESS: at 94.48% examples, 348925 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:11:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:11:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:11:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:11:57: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 6.4s, 350533 effective words/s\n",
      "INFO - 14:11:58: EPOCH 2 - PROGRESS: at 16.12% examples, 358145 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:11:59: EPOCH 2 - PROGRESS: at 32.44% examples, 364668 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:00: EPOCH 2 - PROGRESS: at 49.03% examples, 364243 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:01: EPOCH 2 - PROGRESS: at 65.73% examples, 366524 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:02: EPOCH 2 - PROGRESS: at 81.96% examples, 364514 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:03: EPOCH 2 - PROGRESS: at 98.51% examples, 364802 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:12:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:12:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:12:03: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 6.1s, 366121 effective words/s\n",
      "INFO - 14:12:03: training on a 6000000 raw words (4502374 effective words) took 12.6s, 357673 effective words/s\n",
      "INFO - 14:12:03: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:12:03: collecting all words and their counts\n",
      "INFO - 14:12:03: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:12:03: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4708927042653371\n",
      "(300, 2, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:12:03: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:12:04: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:12:05: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:12:05: Loading a fresh vocabulary\n",
      "INFO - 14:12:05: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:12:05: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:12:05: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:12:05: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:12:05: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:12:06: estimated required memory for 60943 words and 300 dimensions: 176734700 bytes\n",
      "INFO - 14:12:06: resetting layer weights\n",
      "INFO - 14:12:25: training model with 3 workers on 60943 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 14:12:26: EPOCH 1 - PROGRESS: at 13.75% examples, 304505 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:27: EPOCH 1 - PROGRESS: at 28.27% examples, 314037 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:28: EPOCH 1 - PROGRESS: at 43.47% examples, 321385 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:29: EPOCH 1 - PROGRESS: at 58.13% examples, 323327 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:30: EPOCH 1 - PROGRESS: at 73.28% examples, 325111 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:31: EPOCH 1 - PROGRESS: at 88.28% examples, 326204 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:12:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:12:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:12:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:12:32: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 6.9s, 328214 effective words/s\n",
      "INFO - 14:12:33: EPOCH 2 - PROGRESS: at 13.43% examples, 301262 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:34: EPOCH 2 - PROGRESS: at 27.27% examples, 305845 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:35: EPOCH 2 - PROGRESS: at 42.16% examples, 315516 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:36: EPOCH 2 - PROGRESS: at 57.80% examples, 323880 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:12:37: EPOCH 2 - PROGRESS: at 72.65% examples, 323302 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:12:38: EPOCH 2 - PROGRESS: at 89.26% examples, 331336 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:12:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:12:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:12:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:12:38: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 6.7s, 335649 effective words/s\n",
      "INFO - 14:12:38: training on a 6000000 raw words (4502374 effective words) took 13.6s, 331468 effective words/s\n",
      "INFO - 14:12:38: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:12:39: collecting all words and their counts\n",
      "INFO - 14:12:39: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627209821498612\n",
      "(300, 5, 5, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:12:39: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:12:39: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:12:40: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:12:40: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:12:40: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:12:40: Loading a fresh vocabulary\n",
      "INFO - 14:12:40: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:12:40: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:12:41: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:12:41: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:12:41: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:12:41: estimated required memory for 108857 words and 300 dimensions: 315685300 bytes\n",
      "INFO - 14:12:41: resetting layer weights\n",
      "INFO - 14:13:13: training model with 3 workers on 108857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:13:14: EPOCH 1 - PROGRESS: at 13.12% examples, 328166 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:15: EPOCH 1 - PROGRESS: at 25.99% examples, 329223 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:16: EPOCH 1 - PROGRESS: at 38.87% examples, 330298 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:13:17: EPOCH 1 - PROGRESS: at 52.75% examples, 332860 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:18: EPOCH 1 - PROGRESS: at 66.08% examples, 332963 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:19: EPOCH 1 - PROGRESS: at 79.56% examples, 331993 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:20: EPOCH 1 - PROGRESS: at 92.76% examples, 332599 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:13:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:13:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:13:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:13:21: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 7.7s, 333208 effective words/s\n",
      "INFO - 14:13:22: EPOCH 2 - PROGRESS: at 12.82% examples, 324893 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:23: EPOCH 2 - PROGRESS: at 26.64% examples, 333038 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:24: EPOCH 2 - PROGRESS: at 40.21% examples, 335245 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:25: EPOCH 2 - PROGRESS: at 53.84% examples, 337633 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:13:26: EPOCH 2 - PROGRESS: at 67.13% examples, 335549 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:13:27: EPOCH 2 - PROGRESS: at 80.97% examples, 336333 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:28: EPOCH 2 - PROGRESS: at 94.48% examples, 337476 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:13:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:13:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:13:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:13:29: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 7.6s, 337499 effective words/s\n",
      "INFO - 14:13:29: training on a 6000000 raw words (5129408 effective words) took 15.3s, 334751 effective words/s\n",
      "INFO - 14:13:29: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:13:29: collecting all words and their counts\n",
      "INFO - 14:13:29: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4237782894557126\n",
      "(300, 5, 5, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:13:29: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:13:29: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n",
      "INFO - 14:13:29: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:13:29: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:13:29: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:13:30: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:13:30: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:13:30: Loading a fresh vocabulary\n",
      "INFO - 14:13:31: effective_min_count=5 retains 108857 unique words (30% of original 359408, drops 250551)\n",
      "INFO - 14:13:31: effective_min_count=5 leaves 2564704 word corpus (85% of original 3000000, drops 435296)\n",
      "INFO - 14:13:32: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:13:32: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:13:32: downsampling leaves estimated 2564704 word corpus (100.0% of prior 2564704)\n",
      "INFO - 14:13:32: estimated required memory for 108857 words and 300 dimensions: 315685300 bytes\n",
      "INFO - 14:13:32: resetting layer weights\n",
      "INFO - 14:14:06: training model with 3 workers on 108857 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:14:07: EPOCH 1 - PROGRESS: at 11.79% examples, 297100 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:08: EPOCH 1 - PROGRESS: at 23.78% examples, 298060 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:09: EPOCH 1 - PROGRESS: at 35.11% examples, 293264 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:10: EPOCH 1 - PROGRESS: at 48.69% examples, 305872 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:11: EPOCH 1 - PROGRESS: at 62.37% examples, 313562 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:12: EPOCH 1 - PROGRESS: at 75.89% examples, 317611 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:13: EPOCH 1 - PROGRESS: at 89.91% examples, 320766 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:14:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:14:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:14:14: EPOCH - 1 : training on 3000000 raw words (2564704 effective words) took 7.9s, 323752 effective words/s\n",
      "INFO - 14:14:15: EPOCH 2 - PROGRESS: at 13.12% examples, 336652 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:16: EPOCH 2 - PROGRESS: at 24.71% examples, 313163 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:17: EPOCH 2 - PROGRESS: at 35.45% examples, 296495 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:14:18: EPOCH 2 - PROGRESS: at 48.04% examples, 302081 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:19: EPOCH 2 - PROGRESS: at 61.03% examples, 307552 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:14:20: EPOCH 2 - PROGRESS: at 74.84% examples, 312732 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:21: EPOCH 2 - PROGRESS: at 88.27% examples, 316399 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:14:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:14:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:14:22: EPOCH - 2 : training on 3000000 raw words (2564704 effective words) took 8.0s, 320802 effective words/s\n",
      "INFO - 14:14:22: training on a 6000000 raw words (5129408 effective words) took 15.9s, 321937 effective words/s\n",
      "INFO - 14:14:22: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:14:22: collecting all words and their counts\n",
      "INFO - 14:14:22: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261527332211448\n",
      "(300, 5, 10, 0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:14:22: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:14:22: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:14:23: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:14:23: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:14:23: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:14:23: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:14:23: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:14:23: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:14:23: Loading a fresh vocabulary\n",
      "INFO - 14:14:23: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:14:23: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:14:24: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:14:24: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:14:24: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:14:24: estimated required memory for 60943 words and 300 dimensions: 176734700 bytes\n",
      "INFO - 14:14:24: resetting layer weights\n",
      "INFO - 14:14:41: training model with 3 workers on 60943 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:14:42: EPOCH 1 - PROGRESS: at 14.81% examples, 333040 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:43: EPOCH 1 - PROGRESS: at 30.15% examples, 339754 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:44: EPOCH 1 - PROGRESS: at 44.77% examples, 333738 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:14:45: EPOCH 1 - PROGRESS: at 60.03% examples, 335530 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:46: EPOCH 1 - PROGRESS: at 75.89% examples, 338127 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:47: EPOCH 1 - PROGRESS: at 91.55% examples, 337513 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:14:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:14:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:14:47: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 6.6s, 338897 effective words/s\n",
      "INFO - 14:14:48: EPOCH 2 - PROGRESS: at 15.76% examples, 345118 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:49: EPOCH 2 - PROGRESS: at 31.78% examples, 352073 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:14:50: EPOCH 2 - PROGRESS: at 48.08% examples, 352432 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:51: EPOCH 2 - PROGRESS: at 64.06% examples, 353333 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:52: EPOCH 2 - PROGRESS: at 80.25% examples, 352451 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:53: EPOCH 2 - PROGRESS: at 96.15% examples, 353244 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:14:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:14:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:14:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:14:54: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 6.4s, 352765 effective words/s\n",
      "INFO - 14:14:54: training on a 6000000 raw words (4502374 effective words) took 13.0s, 345318 effective words/s\n",
      "INFO - 14:14:54: precomputing L2-norms of word weight vectors\n",
      "INFO - 14:14:54: collecting all words and their counts\n",
      "INFO - 14:14:54: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:14:54: PROGRESS: at sentence #5000, processed 237915 words, keeping 89055 word types\n",
      "INFO - 14:14:54: PROGRESS: at sentence #10000, processed 478486 words, keeping 138858 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3520167415895233\n",
      "(300, 5, 10, 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:14:54: PROGRESS: at sentence #15000, processed 716817 words, keeping 175553 word types\n",
      "INFO - 14:14:54: PROGRESS: at sentence #20000, processed 963957 words, keeping 206354 word types\n",
      "INFO - 14:14:54: PROGRESS: at sentence #25000, processed 1199236 words, keeping 231178 word types\n",
      "INFO - 14:14:54: PROGRESS: at sentence #30000, processed 1440365 words, keeping 253765 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #35000, processed 1676578 words, keeping 273056 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #40000, processed 1914864 words, keeping 291628 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #45000, processed 2146102 words, keeping 307766 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #50000, processed 2385823 words, keeping 323934 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #55000, processed 2621765 words, keeping 338407 word types\n",
      "INFO - 14:14:55: PROGRESS: at sentence #60000, processed 2862554 words, keeping 351953 word types\n",
      "INFO - 14:14:55: collected 359408 word types from a corpus of 3000000 raw words and 62897 sentences\n",
      "INFO - 14:14:55: Loading a fresh vocabulary\n",
      "INFO - 14:14:56: effective_min_count=10 retains 60943 unique words (16% of original 359408, drops 298465)\n",
      "INFO - 14:14:56: effective_min_count=10 leaves 2251187 word corpus (75% of original 3000000, drops 748813)\n",
      "INFO - 14:14:56: deleting the raw counts dictionary of 359408 items\n",
      "INFO - 14:14:56: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 14:14:56: downsampling leaves estimated 2251187 word corpus (100.0% of prior 2251187)\n",
      "INFO - 14:14:56: estimated required memory for 60943 words and 300 dimensions: 176734700 bytes\n",
      "INFO - 14:14:56: resetting layer weights\n",
      "INFO - 14:15:15: training model with 3 workers on 60943 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 14:15:16: EPOCH 1 - PROGRESS: at 14.81% examples, 325871 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:15:17: EPOCH 1 - PROGRESS: at 29.79% examples, 332142 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:15:18: EPOCH 1 - PROGRESS: at 45.44% examples, 336481 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:19: EPOCH 1 - PROGRESS: at 60.69% examples, 337681 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:20: EPOCH 1 - PROGRESS: at 76.85% examples, 339669 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:15:21: EPOCH 1 - PROGRESS: at 93.12% examples, 341610 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:15:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:15:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:15:21: EPOCH - 1 : training on 3000000 raw words (2251187 effective words) took 6.6s, 343451 effective words/s\n",
      "INFO - 14:15:22: EPOCH 2 - PROGRESS: at 15.47% examples, 341912 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:23: EPOCH 2 - PROGRESS: at 31.12% examples, 348084 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:24: EPOCH 2 - PROGRESS: at 47.07% examples, 350147 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:25: EPOCH 2 - PROGRESS: at 63.04% examples, 351727 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:26: EPOCH 2 - PROGRESS: at 78.21% examples, 348267 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 14:15:27: EPOCH 2 - PROGRESS: at 93.79% examples, 347879 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 14:15:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:15:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:15:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:15:28: EPOCH - 2 : training on 3000000 raw words (2251187 effective words) took 6.5s, 347657 effective words/s\n",
      "INFO - 14:15:28: training on a 6000000 raw words (4502374 effective words) took 13.0s, 345126 effective words/s\n",
      "INFO - 14:15:28: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7629580381573797\n",
      "Best score - 0.8351309505773115 Best parms -  (200, 5, 5, 0.025)\n"
     ]
    }
   ],
   "source": [
    "cust_param_search(parm_dict,sentences,test_set,most_viewed_element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lecture4",
   "language": "python",
   "name": ".lecture4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
